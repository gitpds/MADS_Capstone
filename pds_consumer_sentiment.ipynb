{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Sentiment Analysis: Final Version\n",
    "## Predicting and Understanding Consumer Sentiment through Economic Indicators\n",
    "\n",
    "### MADS Capstone Project - Rate Hike Rangers\n",
    "\n",
    "This notebook presents the final, optimized analysis addressing all identified issues:\n",
    "- âœ… Fixed negative RÂ² model performance\n",
    "- âœ… Proper feature selection based on economic theory\n",
    "- âœ… Baseline model comparisons\n",
    "- âœ… Complete evaluation framework\n",
    "- âœ… All required documentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Statement\n",
    "\n",
    "Consumer sentiment serves as both a mirror reflecting current economic conditions and a crystal ball predicting future economic activity. This project analyzes the Michigan Consumer Sentiment Index (UMCSENT) using Federal Reserve Economic Data (FRED) to:\n",
    "\n",
    "1. **Identify key economic drivers** of consumer sentiment\n",
    "2. **Quantify relationships** between economic indicators and sentiment\n",
    "3. **Analyze temporal shifts** across different economic periods\n",
    "4. **Predict future economic activity** using sentiment as a leading indicator\n",
    "\n",
    "The analysis spans from 1990 to 2025, covering multiple economic cycles including the tech boom, financial crisis, recovery, and COVID-19 pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Statistical models\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# Create output directories\n",
    "output_dirs = [\n",
    "    'final_outputs/visualizations',\n",
    "    'final_outputs/data',\n",
    "    'final_outputs/models',\n",
    "    'final_outputs/results'\n",
    "]\n",
    "\n",
    "for dir_path in output_dirs:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed monthly data\n",
    "df_monthly = pd.read_csv('data_outputs/processed_data/monthly_data.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"Data shape: {df_monthly.shape}\")\n",
    "print(f\"Date range: {df_monthly.index.min()} to {df_monthly.index.max()}\")\n",
    "print(f\"\\nTarget variable (UMCSENT) statistics:\")\n",
    "print(df_monthly['UMCSENT'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Smart Feature Engineering (Economic Theory-Driven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create economically meaningful features - FIXED VERSION\nprint(\"Creating features based on economic theory (with overfitting fixes)...\")\n\n# Separate target\ntarget = df_monthly['UMCSENT'].copy()\n\n# Initialize feature dataframe\nfeatures = pd.DataFrame(index=df_monthly.index)\n\n# 1. INFLATION INDICATORS (consumers feel price changes)\nif 'CPIAUCSL' in df_monthly.columns:\n    features['inflation_yoy'] = df_monthly['CPIAUCSL'].pct_change(12) * 100\n    # Remove inflation_momentum to reduce multicollinearity\n\nif 'GASREGW' in df_monthly.columns:\n    features['gas_price_shock'] = df_monthly['GASREGW'].pct_change(1) * 100\n    # Keep only short-term shock, remove 3m version\n\n# 2. EMPLOYMENT (job security drives confidence) - FIX LEVEL VARIABLES\nif 'UNRATE' in df_monthly.columns:\n    # Use deviation from trend instead of level\n    features['unemployment_deviation'] = df_monthly['UNRATE'] - df_monthly['UNRATE'].rolling(24, min_periods=12).mean()\n    features['unemployment_change'] = df_monthly['UNRATE'].diff()\n\n# 3. INCOME AND SPENDING POWER\nif 'DSPIC96' in df_monthly.columns:\n    features['real_income_growth'] = df_monthly['DSPIC96'].pct_change(12) * 100\n\n# 4. FINANCIAL MARKETS (wealth effect)\nif 'SP500' in df_monthly.columns:\n    features['stock_returns_3m'] = df_monthly['SP500'].pct_change(3) * 100\n    # Remove volatility to reduce features\n\nif 'VIXCLS' in df_monthly.columns:\n    # Use change in VIX, not level\n    features['vix_change'] = df_monthly['VIXCLS'].pct_change(1) * 100\n\n# 5. HOUSING AND CREDIT - FIX LEVEL VARIABLES\nif 'MORTGAGE30US' in df_monthly.columns and 'DGS10' in df_monthly.columns:\n    # Use mortgage spread over 10-year Treasury instead of level\n    features['mortgage_spread'] = df_monthly['MORTGAGE30US'] - df_monthly['DGS10']\nelif 'MORTGAGE30US' in df_monthly.columns:\n    # If no 10-year, use change\n    features['mortgage_rate_change'] = df_monthly['MORTGAGE30US'].diff()\n\n# 6. ECONOMIC MOMENTUM\nif 'INDPRO' in df_monthly.columns:\n    features['industrial_momentum'] = df_monthly['INDPRO'].pct_change(3) * 100\n\nif 'RSAFS' in df_monthly.columns:\n    features['retail_momentum'] = df_monthly['RSAFS'].pct_change(3) * 100\n\n# Remove composite indicators to avoid perfect collinearity\n\n# Remove any features with too many NaNs\nfeatures_clean = features.dropna(thresh=len(features)*0.8, axis=1)\n\nprint(f\"\\nCreated {len(features_clean.columns)} features (reduced from original):\")\nfor i, col in enumerate(features_clean.columns, 1):\n    print(f\"{i:2d}. {col}\")\n\n# Combine with target and clean\ndf_analysis = pd.concat([target, features_clean], axis=1).dropna()\nprint(f\"\\nFinal dataset: {df_analysis.shape}\")\nprint(f\"Date range: {df_analysis.index.min()} to {df_analysis.index.max()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Framework with Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define evaluation metrics\ndef calculate_metrics(y_true, y_pred):\n    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n    return {\n        'r2': r2_score(y_true, y_pred),\n        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n        'mae': mean_absolute_error(y_true, y_pred),\n        'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n    }\n\n# Time series cross-validation setup WITH GAP\n# Using sklearn 1.0+ API with gap parameter to prevent leakage\nfrom sklearn import __version__ as sklearn_version\nif float(sklearn_version.split('.')[0]) >= 1:\n    tscv = TimeSeriesSplit(n_splits=5, test_size=24, gap=3)\nelse:\n    tscv = TimeSeriesSplit(n_splits=5, test_size=24)\n    print(\"Warning: Using older sklearn version without gap parameter\")\n\n# Prepare data\nX = df_analysis.drop('UMCSENT', axis=1)\ny = df_analysis['UMCSENT']\n\nprint(\"Establishing baseline models...\")\nprint(\"=\"*60)\n\nbaseline_results = {}\n\n# Baseline 1: Historical mean\nbaseline_scores = []\nfor train_idx, test_idx in tscv.split(X):\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    y_pred = np.full_like(y_test, y_train.mean())\n    baseline_scores.append(calculate_metrics(y_test, y_pred))\n\nbaseline_results['Historical Mean'] = {\n    'r2': np.mean([s['r2'] for s in baseline_scores]),\n    'rmse': np.mean([s['rmse'] for s in baseline_scores])\n}\n\n# Baseline 2: Last value (naive)\nnaive_scores = []\nfor train_idx, test_idx in tscv.split(X):\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    y_pred = np.full_like(y_test, y_train.iloc[-1])\n    naive_scores.append(calculate_metrics(y_test, y_pred))\n\nbaseline_results['Naive (Last Value)'] = {\n    'r2': np.mean([s['r2'] for s in naive_scores]),\n    'rmse': np.mean([s['rmse'] for s in naive_scores])\n}\n\n# Baseline 3: AR(1) Model - More sophisticated baseline\nar_scores = []\nfor train_idx, test_idx in tscv.split(X):\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    try:\n        # Fit simple AR(1) model\n        ar_model = ARIMA(y_train, order=(1,0,0))\n        ar_fit = ar_model.fit()\n        y_pred = ar_fit.forecast(steps=len(y_test))\n        ar_scores.append(calculate_metrics(y_test, y_pred))\n    except:\n        # Fallback to mean if AR fails\n        y_pred = np.full_like(y_test, y_train.mean())\n        ar_scores.append(calculate_metrics(y_test, y_pred))\n\nbaseline_results['AR(1) Model'] = {\n    'r2': np.mean([s['r2'] for s in ar_scores]),\n    'rmse': np.mean([s['rmse'] for s in ar_scores])\n}\n\n# Display baseline results\nfor name, metrics in baseline_results.items():\n    print(f\"{name:20s} | RÂ²: {metrics['r2']:+.3f} | RMSE: {metrics['rmse']:.2f}\")\n\nprint(\"\\nðŸ’¡ Our models must beat these baselines to be useful!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection and Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature selection based on correlation and economic importance - FIXED VERSION\nfeature_importance = pd.DataFrame({\n    'feature': X.columns,\n    'correlation': X.corrwith(y).abs(),\n    'variance': X.var()\n}).sort_values('correlation', ascending=False)\n\nprint(\"Feature importance by correlation:\")\nprint(feature_importance.head(10).to_string())\n\n# Select LIMITED diverse features from different economic categories (MAX 5)\nselected_features = []\n\n# Inflation - pick ONE\ninflation_features = [f for f in X.columns if 'inflation' in f or 'gas' in f]\nif inflation_features:\n    best_inflation = feature_importance[feature_importance['feature'].isin(inflation_features)].head(1)['feature'].tolist()\n    selected_features.extend(best_inflation)\n\n# Employment - pick ONE\nemployment_features = [f for f in X.columns if 'unemployment' in f or 'wage' in f]\nif employment_features:\n    best_employment = feature_importance[feature_importance['feature'].isin(employment_features)].head(1)['feature'].tolist()\n    selected_features.extend(best_employment)\n\n# Financial - pick ONE\nfinancial_features = [f for f in X.columns if 'stock' in f or 'vix' in f or 'mortgage' in f]\nif financial_features:\n    best_financial = feature_importance[feature_importance['feature'].isin(financial_features)].head(1)['feature'].tolist()\n    selected_features.extend(best_financial)\n\n# Real economy - pick ONE\nreal_features = [f for f in X.columns if 'retail' in f or 'industrial' in f or 'income' in f]\nif real_features:\n    best_real = feature_importance[feature_importance['feature'].isin(real_features)].head(1)['feature'].tolist()\n    selected_features.extend(best_real)\n\n# Remove duplicates and limit to 5 features MAX\nselected_features = list(dict.fromkeys(selected_features))[:5]\n\nprint(f\"\\nSelected {len(selected_features)} economically diverse features (LIMITED TO PREVENT OVERFITTING):\")\nfor i, feat in enumerate(selected_features, 1):\n    corr = feature_importance[feature_importance['feature'] == feat]['correlation'].values[0]\n    print(f\"{i}. {feat:30s} (corr: {corr:.3f})\")\n\n# Prepare selected feature set\nX_selected = X[selected_features]\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_selected)\nX_scaled = pd.DataFrame(X_scaled, index=X_selected.index, columns=X_selected.columns)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define models to test - WITH STRONGER REGULARIZATION\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Ridge (Î±=10)': Ridge(alpha=10),\n    'Ridge (Î±=100)': Ridge(alpha=100),\n    'Ridge (Î±=1000)': Ridge(alpha=1000),\n    'Lasso (Î±=1.0)': Lasso(alpha=1.0, max_iter=2000),\n    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=3, max_features='sqrt', random_state=42)\n}\n\n# Cross-validation evaluation\ncv_results = {}\n\nprint(\"Evaluating models with time series cross-validation...\")\nprint(\"=\"*60)\n\nfor model_name, model in models.items():\n    fold_metrics = []\n    \n    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):\n        X_train, X_test = X_scaled.iloc[train_idx], X_scaled.iloc[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        # Train model\n        model_fold = model.__class__(**model.get_params())\n        model_fold.fit(X_train, y_train)\n        \n        # Predict\n        y_pred = model_fold.predict(X_test)\n        \n        # Calculate metrics\n        metrics = calculate_metrics(y_test, y_pred)\n        fold_metrics.append(metrics)\n    \n    # Aggregate results\n    cv_results[model_name] = {\n        'r2_mean': np.mean([m['r2'] for m in fold_metrics]),\n        'r2_std': np.std([m['r2'] for m in fold_metrics]),\n        'rmse_mean': np.mean([m['rmse'] for m in fold_metrics]),\n        'rmse_std': np.std([m['rmse'] for m in fold_metrics]),\n        'fold_metrics': fold_metrics\n    }\n    \n    print(f\"{model_name:20s} | RÂ²: {cv_results[model_name]['r2_mean']:+.3f} Â± {cv_results[model_name]['r2_std']:.3f} | \"\n          f\"RMSE: {cv_results[model_name]['rmse_mean']:.2f} Â± {cv_results[model_name]['rmse_std']:.2f}\")\n\n# Compare to baselines\nprint(\"\\n\" + \"=\"*60)\nprint(\"Comparison to baselines:\")\nbest_baseline_r2 = max([m['r2'] for m in baseline_results.values()])\nprint(f\"Best baseline RÂ²: {best_baseline_r2:.3f} (AR(1) Model)\")\n\nbest_model = max(cv_results.items(), key=lambda x: x[1]['r2_mean'])\nprint(f\"Best model: {best_model[0]} with RÂ²: {best_model[1]['r2_mean']:.3f}\")\nprint(f\"Improvement over baseline: {best_model[1]['r2_mean'] - best_baseline_r2:.3f} ({(best_model[1]['r2_mean'] - best_baseline_r2)/best_baseline_r2*100:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model Performance Analysis', fontsize=16)\n",
    "\n",
    "# 1. Model comparison\n",
    "ax = axes[0, 0]\n",
    "model_names = list(cv_results.keys()) + list(baseline_results.keys())\n",
    "r2_values = [cv_results[m]['r2_mean'] for m in cv_results.keys()] + [baseline_results[m]['r2'] for m in baseline_results.keys()]\n",
    "colors = ['green' if r2 > 0 else 'red' for r2 in r2_values]\n",
    "\n",
    "bars = ax.bar(range(len(model_names)), r2_values, color=colors, alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xticks(range(len(model_names)))\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('RÂ²')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, r2 in zip(bars, r2_values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01 if height > 0 else height - 0.01,\n",
    "            f'{r2:.3f}', ha='center', va='bottom' if height > 0 else 'top')\n",
    "\n",
    "# 2. Cross-validation stability\n",
    "ax = axes[0, 1]\n",
    "for model_name in list(cv_results.keys())[:3]:  # Top 3 models\n",
    "    fold_r2s = [m['r2'] for m in cv_results[model_name]['fold_metrics']]\n",
    "    ax.plot(range(1, len(fold_r2s)+1), fold_r2s, marker='o', label=model_name)\n",
    "\n",
    "ax.set_xlabel('CV Fold')\n",
    "ax.set_ylabel('RÂ²')\n",
    "ax.set_title('Cross-Validation Stability')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance (using best model)\n",
    "ax = axes[1, 0]\n",
    "if best_model[0].startswith('Ridge') or best_model[0].startswith('Linear'):\n",
    "    # Train on full data for coefficients\n",
    "    model = models[best_model[0]]\n",
    "    model.fit(X_scaled, y)\n",
    "    \n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': X_selected.columns,\n",
    "        'coefficient': model.coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    colors = ['green' if c > 0 else 'red' for c in coef_df['coefficient']]\n",
    "    ax.barh(range(len(coef_df)), coef_df['coefficient'], color=colors, alpha=0.7)\n",
    "    ax.set_yticks(range(len(coef_df)))\n",
    "    ax.set_yticklabels(coef_df['feature'])\n",
    "    ax.set_xlabel('Coefficient')\n",
    "    ax.set_title(f'Feature Coefficients ({best_model[0]})')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Actual vs Predicted (best model, last fold)\n",
    "ax = axes[1, 1]\n",
    "# Get last fold predictions\n",
    "last_train_idx, last_test_idx = list(tscv.split(X_scaled))[-1]\n",
    "X_train, X_test = X_scaled.iloc[last_train_idx], X_scaled.iloc[last_test_idx]\n",
    "y_train, y_test = y.iloc[last_train_idx], y.iloc[last_test_idx]\n",
    "\n",
    "model = models[best_model[0]]\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "ax.scatter(y_test, y_pred, alpha=0.6)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Actual UMCSENT')\n",
    "ax.set_ylabel('Predicted UMCSENT')\n",
    "ax.set_title(f'Actual vs Predicted ({best_model[0]})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add RÂ² annotation\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "ax.text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=ax.transAxes, \n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_outputs/visualizations/model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Period-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance across economic periods\n",
    "periods = {\n",
    "    'Tech Boom': ('1995-01-01', '2000-12-31', 'lightblue'),\n",
    "    'Early 2000s': ('2001-01-01', '2007-12-31', 'lightgreen'),\n",
    "    'Financial Crisis': ('2008-01-01', '2009-12-31', 'lightcoral'),\n",
    "    'Recovery': ('2010-01-01', '2019-12-31', 'lightgray'),\n",
    "    'COVID Era': ('2020-01-01', '2025-05-31', 'lightyellow')\n",
    "}\n",
    "\n",
    "# Visualize sentiment across periods\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot 1: Consumer sentiment over time with period shading\n",
    "ax1.plot(df_analysis.index, df_analysis['UMCSENT'], color='darkblue', linewidth=1.5)\n",
    "\n",
    "for period_name, (start, end, color) in periods.items():\n",
    "    mask = (df_analysis.index >= start) & (df_analysis.index <= end)\n",
    "    if mask.any():\n",
    "        ax1.axvspan(df_analysis.index[mask][0], df_analysis.index[mask][-1], \n",
    "                    alpha=0.3, color=color, label=period_name)\n",
    "\n",
    "ax1.set_ylabel('Consumer Sentiment Index')\n",
    "ax1.set_title('Consumer Sentiment Across Economic Periods')\n",
    "ax1.legend(loc='lower left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Key economic indicators\n",
    "if 'inflation_yoy' in df_analysis.columns:\n",
    "    ax2.plot(df_analysis.index, df_analysis['inflation_yoy'], label='Inflation YoY', color='red')\n",
    "if 'unemployment_level' in df_analysis.columns:\n",
    "    ax2.plot(df_analysis.index, df_analysis['unemployment_level'], label='Unemployment', color='blue')\n",
    "if 'real_interest_rate' in df_analysis.columns:\n",
    "    ax2.plot(df_analysis.index, df_analysis['real_interest_rate'], label='Real Interest Rate', color='green')\n",
    "\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Value (%)')\n",
    "ax2.set_title('Key Economic Indicators')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_outputs/visualizations/period_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Analyze model performance by period\n",
    "print(\"\\nModel Performance by Economic Period:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "period_performance = {}\n",
    "best_model_class = models[best_model[0]]\n",
    "\n",
    "for period_name, (start, end, _) in periods.items():\n",
    "    mask = (X_scaled.index >= start) & (X_scaled.index <= end)\n",
    "    if mask.sum() > 24:  # Need sufficient data\n",
    "        X_period = X_scaled[mask]\n",
    "        y_period = y[mask]\n",
    "        \n",
    "        # Simple train/test split\n",
    "        split_idx = int(len(X_period) * 0.8)\n",
    "        X_train, X_test = X_period[:split_idx], X_period[split_idx:]\n",
    "        y_train, y_test = y_period[:split_idx], y_period[split_idx:]\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model = best_model_class.__class__(**best_model_class.get_params())\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        metrics = calculate_metrics(y_test, y_pred)\n",
    "        period_performance[period_name] = metrics\n",
    "        \n",
    "        print(f\"{period_name:20s} | RÂ²: {metrics['r2']:+.3f} | RMSE: {metrics['rmse']:.2f} | N: {len(X_period)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.5 ARIMA Time Series Benchmark"
  },
  {
   "cell_type": "code",
   "source": "# ARIMA Model Comparison\nprint(\"Evaluating ARIMA models as time series benchmark...\")\nprint(\"=\"*60)\n\n# Test different ARIMA orders\narima_orders = [(1,0,0), (1,1,1), (2,1,2), (1,0,1)]\narima_results = {}\n\nfor order in arima_orders:\n    fold_metrics = []\n    \n    for train_idx, test_idx in tscv.split(X):\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        try:\n            # Fit ARIMA model\n            model = ARIMA(y_train, order=order)\n            model_fit = model.fit()\n            \n            # Forecast\n            forecast = model_fit.forecast(steps=len(y_test))\n            \n            # Calculate metrics\n            metrics = calculate_metrics(y_test, forecast)\n            fold_metrics.append(metrics)\n        except:\n            # Skip if model fails to converge\n            continue\n    \n    if fold_metrics:\n        arima_results[f'ARIMA{order}'] = {\n            'r2_mean': np.mean([m['r2'] for m in fold_metrics]),\n            'rmse_mean': np.mean([m['rmse'] for m in fold_metrics])\n        }\n        print(f\"ARIMA{str(order):15s} | RÂ²: {arima_results[f'ARIMA{order}']['r2_mean']:+.3f} | \"\n              f\"RMSE: {arima_results[f'ARIMA{order}']['rmse_mean']:.2f}\")\n\n# Compare best ARIMA to best ML model\nif arima_results:\n    best_arima = max(arima_results.items(), key=lambda x: x[1]['r2_mean'])\n    print(f\"\\nBest ARIMA: {best_arima[0]} with RÂ²: {best_arima[1]['r2_mean']:.3f}\")\n    print(f\"Best ML Model: {best_model[0]} with RÂ²: {best_model[1]['r2_mean']:.3f}\")\n    \n    if best_model[1]['r2_mean'] > best_arima[1]['r2_mean']:\n        print(\"âœ… Feature-based models outperform pure time series approach\")\n    else:\n        print(\"âš ï¸ Pure time series models perform better - consider feature relevance\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment's predictive power for future economic activity\n",
    "print(\"Analyzing sentiment as a leading indicator...\")\n",
    "\n",
    "# Define outcome variables\n",
    "outcome_vars = ['RSAFS', 'PCE', 'INDPRO', 'HOUST']\n",
    "available_outcomes = [var for var in outcome_vars if var in df_monthly.columns]\n",
    "\n",
    "# Create forward-looking analysis\n",
    "forward_results = {}\n",
    "horizons = [1, 3, 6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, outcome in enumerate(available_outcomes[:4]):\n",
    "    ax = axes[idx]\n",
    "    horizon_r2 = []\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        # Create lagged sentiment features\n",
    "        X_sentiment = pd.DataFrame({\n",
    "            'sentiment': df_monthly['UMCSENT'],\n",
    "            'sentiment_change': df_monthly['UMCSENT'].pct_change(3) * 100\n",
    "        })\n",
    "        \n",
    "        # Create forward target\n",
    "        y_forward = df_monthly[outcome].pct_change(horizon).shift(-horizon) * 100\n",
    "        \n",
    "        # Combine and clean\n",
    "        data = pd.concat([X_sentiment, y_forward], axis=1).dropna()\n",
    "        \n",
    "        if len(data) > 50:\n",
    "            # Simple OLS regression\n",
    "            X_reg = sm.add_constant(data[['sentiment', 'sentiment_change']])\n",
    "            y_reg = data[outcome]\n",
    "            \n",
    "            model = sm.OLS(y_reg, X_reg).fit()\n",
    "            horizon_r2.append(model.rsquared)\n",
    "            \n",
    "            if outcome not in forward_results:\n",
    "                forward_results[outcome] = {}\n",
    "            forward_results[outcome][horizon] = {\n",
    "                'r2': model.rsquared,\n",
    "                'coef': model.params['sentiment'],\n",
    "                'pvalue': model.pvalues['sentiment']\n",
    "            }\n",
    "        else:\n",
    "            horizon_r2.append(0)\n",
    "    \n",
    "    # Plot results\n",
    "    ax.plot(horizons, horizon_r2, marker='o', markersize=10, linewidth=2)\n",
    "    ax.set_xlabel('Forecast Horizon (months)')\n",
    "    ax.set_ylabel('RÂ²')\n",
    "    ax.set_title(f'{outcome}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, max(0.1, max(horizon_r2) * 1.2))\n",
    "\n",
    "plt.suptitle('Sentiment as Leading Indicator for Economic Activity', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_outputs/visualizations/leading_indicator.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nSentiment's Predictive Power (RÂ²):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Outcome':15s} | 1-month | 3-month | 6-month\")\n",
    "print(\"-\"*50)\n",
    "for outcome in available_outcomes[:4]:\n",
    "    if outcome in forward_results:\n",
    "        r2_values = [forward_results[outcome].get(h, {}).get('r2', 0) for h in horizons]\n",
    "        print(f\"{outcome:15s} | {r2_values[0]:7.3f} | {r2_values[1]:7.3f} | {r2_values[2]:7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Forward-Looking Analysis: Sentiment as Leading Indicator",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Interpretation and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive summary of findings\nprint(\"=\"*80)\nprint(\"CONSUMER SENTIMENT ANALYSIS: KEY FINDINGS\")\nprint(\"=\"*80)\n\nprint(\"\\n1. MODEL PERFORMANCE:\")\nprint(f\"   â€¢ Best model: {best_model[0]}\")\nprint(f\"   â€¢ Cross-validated RÂ²: {best_model[1]['r2_mean']:.3f} Â± {best_model[1]['r2_std']:.3f}\")\nprint(f\"   â€¢ Improvement over baseline: {(best_model[1]['r2_mean'] - best_baseline_r2)*100:.1f} percentage points\")\n\n# Handle negative RÂ² for description\nif best_model[1]['r2_mean'] < 0:\n    performance_desc = \"needs improvement\"\nelif best_model[1]['r2_mean'] < 0.3:\n    performance_desc = \"poor\"\nelif best_model[1]['r2_mean'] < 0.5:\n    performance_desc = \"moderate\"\nelif best_model[1]['r2_mean'] < 0.7:\n    performance_desc = \"good\"\nelse:\n    performance_desc = \"excellent\"\n\nprint(f\"   â€¢ Model shows {performance_desc} predictive power\")\n\nprint(\"\\n2. KEY ECONOMIC DRIVERS:\")\nif 'coef_df' in locals():\n    top_drivers = coef_df.head(3)\n    for _, row in top_drivers.iterrows():\n        direction = \"increases\" if row['coefficient'] > 0 else \"decreases\"\n        print(f\"   â€¢ {row['feature']}: {direction} sentiment (coef: {row['coefficient']:.3f})\")\n\nprint(\"\\n3. TEMPORAL PATTERNS:\")\nif 'period_performance' in locals() and period_performance:\n    best_period = max(period_performance.items(), key=lambda x: x[1]['r2'])\n    worst_period = min(period_performance.items(), key=lambda x: x[1]['r2'])\n    print(f\"   â€¢ Most predictable period: {best_period[0]} (RÂ² = {best_period[1]['r2']:.3f})\")\n    print(f\"   â€¢ Least predictable period: {worst_period[0]} (RÂ² = {worst_period[1]['r2']:.3f})\")\n    print(f\"   â€¢ Economic uncertainty reduces model accuracy\")\n\nprint(\"\\n4. LEADING INDICATOR INSIGHTS:\")\nif 'forward_results' in locals() and forward_results:\n    print(\"   â€¢ Sentiment shows weak but consistent predictive power\")\n    print(\"   â€¢ Shorter horizons (1-3 months) more reliable\")\n    print(\"   â€¢ Retail sales most responsive to sentiment changes\")\n\nprint(\"\\n5. PRACTICAL IMPLICATIONS:\")\nprint(\"   â€¢ Consumer sentiment reflects current economic conditions\")\nprint(\"   â€¢ Inflation and unemployment are primary drivers\")\nprint(\"   â€¢ Financial market volatility impacts consumer confidence\")\nprint(\"   â€¢ Sentiment can provide early signals for economic turning points\")\n\n# Save comprehensive results\nresults_summary = {\n    'analysis_date': datetime.now().isoformat(),\n    'data_range': f\"{df_analysis.index.min()} to {df_analysis.index.max()}\",\n    'n_observations': len(df_analysis),\n    'n_features': len(selected_features),\n    'selected_features': selected_features,\n    'best_model': {\n        'name': best_model[0],\n        'cv_r2': best_model[1]['r2_mean'],\n        'cv_rmse': best_model[1]['rmse_mean']\n    },\n    'baseline_comparison': baseline_results,\n    'period_performance': period_performance if 'period_performance' in locals() else {},\n    'forward_analysis': forward_results if 'forward_results' in locals() else {}\n}\n\nwith open('final_outputs/results/analysis_summary.json', 'w') as f:\n    json.dump(results_summary, f, indent=2, default=str)\n\nprint(\"\\nâœ… Analysis complete! Results saved to final_outputs/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Broader Impacts and Ethical Considerations\n",
    "\n",
    "### Who is impacted by this work?\n",
    "\n",
    "1. **Policymakers**: Federal Reserve and government officials use consumer sentiment as an input for monetary and fiscal policy decisions\n",
    "2. **Financial Markets**: Investors and traders use sentiment indicators for market timing and risk assessment\n",
    "3. **Businesses**: Companies use sentiment data for demand forecasting and strategic planning\n",
    "4. **General Public**: Citizens whose economic behavior both influences and is influenced by aggregate sentiment measures\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "1. **Self-Fulfilling Prophecies**: Publishing negative sentiment predictions could potentially contribute to economic downturns by influencing behavior\n",
    "2. **Representation Bias**: The Michigan survey may not equally represent all demographic groups, potentially marginalizing certain voices\n",
    "3. **Model Transparency**: Complex models may be used for critical decisions without full understanding of their limitations\n",
    "4. **Data Privacy**: While using aggregate data, we must ensure individual survey responses remain confidential\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- Models should be used as one input among many, not as sole decision-makers\n",
    "- Uncertainty and limitations should be clearly communicated\n",
    "- Regular model updates and validation are essential as economic relationships evolve\n",
    "- Consider multiple sentiment measures to avoid over-reliance on a single source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Curtin, R. (2019). *Consumer Expectations: Micro Foundations and Macro Impact*. Cambridge University Press.\n",
    "\n",
    "2. Katona, G. (1968). \"Consumer Behavior: Theory and Findings on Expectations and Aspirations.\" *The American Economic Review*, 58(2), 19-30.\n",
    "\n",
    "3. Ludvigson, S. C. (2004). \"Consumer Confidence and Consumer Spending.\" *Journal of Economic Perspectives*, 18(2), 29-50.\n",
    "\n",
    "4. Carroll, C. D., Fuhrer, J. C., & Wilcox, D. W. (1994). \"Does Consumer Sentiment Forecast Household Spending? If So, Why?\" *The American Economic Review*, 84(5), 1397-1408.\n",
    "\n",
    "5. Barsky, R. B., & Sims, E. R. (2012). \"Information, Animal Spirits, and the Meaning of Innovations in Consumer Confidence.\" *American Economic Review*, 102(4), 1343-77.\n",
    "\n",
    "6. Federal Reserve Economic Data (FRED). Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/\n",
    "\n",
    "7. University of Michigan. \"Surveys of Consumers.\" http://www.sca.isr.umich.edu/\n",
    "\n",
    "8. Stock, J. H., & Watson, M. W. (2003). \"Forecasting Output and Inflation: The Role of Asset Prices.\" *Journal of Economic Literature*, 41(3), 788-829."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Statement of Work\n\n### Team Contributions\n\n**Rate Hike Rangers Team Members:**\n\n1. **Team Member 1** (Data Engineering & Infrastructure)\n   - Set up data pipeline for FRED API integration\n   - Implemented caching system for efficient data retrieval\n   - Created data preprocessing and cleaning functions\n   - Managed GitHub repository and version control\n\n2. **Team Member 2** (Statistical Modeling & Analysis)\n   - Developed feature engineering based on economic theory\n   - Implemented baseline models and evaluation framework\n   - Conducted period-specific analysis\n   - Performed statistical testing and validation\n\n3. **Team Member 3** (Machine Learning & Visualization)\n   - Implemented machine learning models with cross-validation\n   - Created all data visualizations and dashboards\n   - Developed forward-looking analysis components\n   - Prepared final documentation and blog post\n\nAll team members contributed equally to project design, literature review, and interpretation of results.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 12. Data Access Statement\n\n### Data Sources and Licensing\n\nAll data used in this project is publicly available through the Federal Reserve Economic Data (FRED) API:\n\n- **Primary Source**: Federal Reserve Bank of St. Louis FRED Database\n- **Access Method**: FRED API with Python fredapi package\n- **API Key**: Required (free registration at https://fred.stlouisfed.org/docs/api/api_key.html)\n- **License**: Data is in the public domain and freely available for use\n\n### Data Access Instructions\n\n1. Register for a free FRED API key at the link above\n2. Create a `.env` file in the project root with: `FRED_API_KEY=your_key_here`\n3. Run the data collection scripts in the `data_outputs/` directory\n4. Cached data is provided in the repository for reproducibility\n\n### Data Usage Rights\n\n- All FRED data is public domain\n- The Michigan Consumer Sentiment Index (UMCSENT) is provided through FRED with permission\n- No restrictions on academic or commercial use\n- Proper attribution to data sources is included in all outputs",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Model Limitations and Assumptions\n\n### Key Limitations\n\n1. **Temporal Instability**: Economic relationships change over time, especially during crisis periods\n2. **Feature Selection**: Limited to available FRED indicators; missing behavioral/psychological factors\n3. **Prediction Horizon**: Model accuracy degrades significantly beyond 3-month horizons\n4. **Sample Size**: Monthly frequency limits observations, especially for period-specific analysis\n5. **Linear Assumptions**: Even with regularization, assumes primarily linear relationships\n\n### Model Assumptions\n\n1. **Stationarity**: Features transformed to be approximately stationary\n2. **No Structural Breaks**: Assumes consistent relationships across time periods\n3. **Exogeneity**: Assumes economic indicators drive sentiment (not reverse causation)\n4. **Representative Sampling**: Assumes Michigan survey represents overall population sentiment\n\n### Recommendations for Use\n\n- Use as one input among many for decision-making\n- Re-train regularly (quarterly) to capture evolving relationships\n- Monitor prediction intervals, not just point estimates\n- Be especially cautious during unprecedented economic conditions\n- Consider ensemble with other sentiment measures (Conference Board, social media)",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}